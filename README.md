# SmartMotion

**Human Activity Recognition Using Deep Learning and Smartphone IMU Sensor Data (UCI HAR Dataset)**

---

## 📌 Project Motivation
My younger brother is autistic and sometimes struggles to communicate his needs clearly. This inspired me to explore motion recognition systems that could support assistive technologies—especially in under-resourced communities like mine in Nigeria. This project aims to use deep learning to recognize human activity from motion data collected by smartphone sensors.

---

## 🎯 Objective
To develop a deep learning model that accurately classifies six types of human movement using data from smartphone accelerometers and gyroscopes:
- Walking
- Walking Upstairs
- Walking Downstairs
- Sitting
- Standing
- Laying

---

## 📊 Dataset
- **Dataset:** UCI HAR (Human Activity Recognition Using Smartphones)
- **Link:** [UCI HAR Dataset](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones)
- **Features:** 561 time-domain and frequency-domain variables collected from IMU signals

---

## 🧠 Model
> (Model-building and training details will be added soon.)
- Data Preprocessing
- LSTM and/or 1D CNN Deep Learning Model
- Evaluation using Accuracy, Confusion Matrix

---

## 🛠 Tools
- Python (Google Colab)
- Pandas, NumPy
- TensorFlow / Keras
- Matplotlib

---

## 📽 Demo (Coming Soon)
Optional video demo and walkthrough will be uploaded before the submission deadline.

---

## 📝 License
This project is open-source under the MIT License. See the [LICENSE](LICENSE) file for more details.
